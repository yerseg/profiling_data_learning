{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "import scipy.stats as stats\n",
    "from geopy.distance import distance as geodist\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_make_dataframes(file_path, sampling_freq, rolling = False, sampling = True):\n",
    "    df = pd.read_csv(file_path, index_col = False, header = None, low_memory = False, \\\n",
    "                     names = ['timestamp', 'accuracy', 'altitude', 'latitude', 'longitude'])\n",
    "    \n",
    "    new_files_dir = \"_datasets\"\n",
    "    if os.path.exists(os.path.join(os.getcwd(), new_files_dir)) is False:\n",
    "        os.mkdir(os.path.join(os.getcwd(), new_files_dir))\n",
    "        \n",
    "    new_files_dir += \"\\\\\" + sampling_freq\n",
    "    if os.path.exists(os.path.join(os.getcwd(), new_files_dir)) is False:\n",
    "        os.mkdir(os.path.join(os.getcwd(), new_files_dir))\n",
    "\n",
    "    df['timestamp'] = df['timestamp'].apply(lambda x: dt.strptime(x, '%d.%m.%Y_%H:%M:%S.%f'))\n",
    "\n",
    "    df.index = pd.DatetimeIndex(df.timestamp)\n",
    "    df = df.sort_index()\n",
    "\n",
    "    df['prev_latitude'] = df['latitude'].shift(1)\n",
    "    df['prev_longitude'] = df['longitude'].shift(1)\n",
    "    df['prev_timestamp'] = df['timestamp'].shift(1)\n",
    "    df['prev_altitude'] = df['altitude'].shift(1)\n",
    "\n",
    "    def get_speed(row):\n",
    "        prev_coords = (row['prev_latitude'], row['prev_longitude'])\n",
    "        curr_coords = (row['latitude'], row['longitude'])\n",
    "        delta = row['timestamp'] - row['prev_timestamp']\n",
    "        if pd.isnull(delta):\n",
    "            return np.nan\n",
    "        time = abs(delta.total_seconds())\n",
    "        if np.isnan(prev_coords[0]) or np.isnan(prev_coords[1]) or np.isnan(curr_coords[0]) or np.isnan(curr_coords[1]):\n",
    "            return np.nan\n",
    "        if time == 0:\n",
    "            return np.nan\n",
    "        return geodist(curr_coords, prev_coords).meters / time\n",
    "\n",
    "    def get_altitude_speed(row):\n",
    "        prev = row['prev_altitude']\n",
    "        curr = row['altitude']\n",
    "        delta = row['timestamp'] - row['prev_timestamp']\n",
    "        if pd.isnull(delta):\n",
    "            return np.nan\n",
    "        time = abs(delta.total_seconds())\n",
    "        if np.isnan(prev) or np.isnan(curr):\n",
    "            return np.nan\n",
    "        if time == 0:\n",
    "            return np.nan\n",
    "        return abs(curr - prev) / time\n",
    "\n",
    "    df['speed'] = df.apply(lambda row: get_speed(row), axis=1)\n",
    "    df['altitude_speed'] = df.apply(lambda row: get_altitude_speed(row), axis=1)\n",
    "\n",
    "    df = df.drop(['prev_latitude', 'prev_longitude', 'prev_altitude'], axis=1)\n",
    "\n",
    "    df['prev_speed'] = df['speed'].shift(1)\n",
    "    df['prev_altitude_speed'] = df['altitude_speed'].shift(1)\n",
    "\n",
    "    def get_acceleration(row):\n",
    "        prev_speed = row['prev_speed']\n",
    "        curr_speed = row['speed']\n",
    "        delta = row['timestamp'] - row['prev_timestamp']\n",
    "        if pd.isnull(delta):\n",
    "            return np.nan\n",
    "        time = abs(delta.total_seconds())\n",
    "        if np.isnan(prev_speed) or np.isnan(curr_speed):\n",
    "            return np.nan\n",
    "        if time == 0:\n",
    "            return np.nan\n",
    "        return curr_speed - prev_speed / time\n",
    "\n",
    "    def get_altitude_acceleration(row):\n",
    "        prev_speed = row['prev_altitude_speed']\n",
    "        curr_speed = row['altitude_speed']\n",
    "        delta = row['timestamp'] - row['prev_timestamp']\n",
    "        if pd.isnull(delta):\n",
    "            return np.nan\n",
    "        time = abs(delta.total_seconds())\n",
    "        if np.isnan(prev_speed) or np.isnan(curr_speed):\n",
    "            return np.nan\n",
    "        if time == 0:\n",
    "            return np.nan\n",
    "        return curr_speed - prev_speed / time\n",
    "\n",
    "    df['acc'] = df.apply(lambda row: get_acceleration(row), axis=1)\n",
    "    df['altitude_acc'] = df.apply(lambda row: get_altitude_acceleration(row), axis=1)\n",
    "\n",
    "    df = df.drop(['prev_altitude_speed', 'prev_speed', 'timestamp', 'prev_timestamp'], axis=1)\n",
    "\n",
    "    def kurt(col):\n",
    "        return stats.kurtosis(col)\n",
    "\n",
    "    common_funcs_list = ['mean', 'var', 'median', 'skew', kurt, 'std']\n",
    "\n",
    "    agg_dict = {\n",
    "        'accuracy': common_funcs_list,\n",
    "        'speed': common_funcs_list,\n",
    "        'altitude_speed': common_funcs_list,\n",
    "        'acc': common_funcs_list,\n",
    "        'altitude_acc': common_funcs_list \n",
    "    }\n",
    "\n",
    "    df_sampling = df.groupby(pd.Grouper(freq = sampling_freq)).agg(agg_dict)\n",
    "\n",
    "    df_sampling.columns = [\"_\".join([str(high_level_name), str(low_level_name)]) \\\n",
    "                               for (high_level_name, low_level_name) in df_sampling.columns.values]\n",
    "    \n",
    "    df_sampling = df_sampling.dropna()\n",
    "    df_sampling = df_sampling.fillna(0)\n",
    "    \n",
    "    index = os.path.basename(file_path).split('_')[-1][0]\n",
    "    \n",
    "    df_sampling.to_csv(new_files_dir + \"\\\\location_sampling_dataset_\" + index + \".csv\")\n",
    "\n",
    "    df_rolling = df.rolling(sampling_freq, min_periods = 1, center = False).agg(agg_dict)\n",
    "\n",
    "    df_rolling = df_rolling.dropna()\n",
    "    df_rolling = df_rolling.fillna(0)\n",
    "\n",
    "    df_rolling.columns = [\"_\".join([str(high_level_name), str(low_level_name)]) \\\n",
    "                       for (high_level_name, low_level_name) in df_rolling.columns.values]\n",
    "    \n",
    "    df_rolling.to_csv(new_files_dir + \"\\\\location_rolling_dataset_\" + index + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_pipeline(files, sampling_freq):\n",
    "    logs = []\n",
    "    for file in files:\n",
    "        logs.append(location_file_process(file))\n",
    "    for t in logs:\n",
    "        print(t['BASE'], sampling_freq)\n",
    "        location_make_dataframes(t['BASE'], sampling_freq, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_FREQs = ['5s', '10s', '30s', '60s', '90s', '120s', '240s', '600s']\n",
    "data_list = [\n",
    "#     \".\\\\raw_data\\\\location_1.data\",\n",
    "#     \".\\\\raw_data\\\\location_2.data\",\n",
    "#     \".\\\\raw_data\\\\location_3.data\",\n",
    "#     \".\\\\raw_data\\\\location_4.data\",\n",
    "#     \".\\\\raw_data\\\\location_5.data\",\n",
    "#     \".\\\\raw_data\\\\location_6.data\",\n",
    "#     \".\\\\raw_data\\\\location_7.data\",\n",
    "    \".\\\\raw_data\\\\location_8.data\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Dev\\nir\\_generated\\location_8.data 5s\n",
      "D:\\Dev\\nir\\_generated\\location_8.data 10s\n",
      "D:\\Dev\\nir\\_generated\\location_8.data 30s\n",
      "D:\\Dev\\nir\\_generated\\location_8.data 60s\n",
      "D:\\Dev\\nir\\_generated\\location_8.data 90s\n",
      "D:\\Dev\\nir\\_generated\\location_8.data 120s\n",
      "D:\\Dev\\nir\\_generated\\location_8.data 240s\n",
      "D:\\Dev\\nir\\_generated\\location_8.data 600s\n"
     ]
    }
   ],
   "source": [
    "for freq in SAMPLING_FREQs: \n",
    "    location_pipeline(data_list, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# location_pipeline([\".\\\\user_1\\\\wifi\\\\wifi_0.data\"], SAMPLING_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location_file_process(\".\\\\location_2.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}