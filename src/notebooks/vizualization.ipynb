{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, plot_roc_curve, make_scorer, f1_score, roc_auc_score, det_curve\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate, LeaveOneGroupOut, PredefinedSplit, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dataframes(path, df_type):\n",
    "    dfs_list = []\n",
    "    dfs_rows_len_list = []\n",
    "    \n",
    "    for user in os.listdir(path):\n",
    "        for file in os.listdir(os.path.join(path, user)):\n",
    "            if file.find(df_type) != -1:\n",
    "                df = pd.read_csv(os.path.join(path, user, file))\n",
    "                \n",
    "                if df_type != 'broadcasts':\n",
    "                    df = df.drop([\"timestamp\"], axis=1)\n",
    "#                 df = (df - df.min()) / (df.max() - df.min())\n",
    "                \n",
    "                df[\"user\"] = int(user.split('_')[1])\n",
    "                \n",
    "                dfs_list.append(df)\n",
    "    \n",
    "    return pd.concat(dfs_list, ignore_index=True)\n",
    "\n",
    "\n",
    "def get_dataframe(path, data_type, window_type, window_size):\n",
    "    return concat_dataframes(os.path.join(path, window_type, window_size), data_type), create_file_for_results(data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '..\\\\..\\\\scripts\\\\_features_all'\n",
    "\n",
    "DATA_TYPE = \"bt\"\n",
    "\n",
    "WINDOW_TYPE = \"rolling\"\n",
    "WINDOW_SIZE = \"60s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = get_dataframe(DATA_PATH, DATA_TYPE, WINDOW_TYPE, WINDOW_SIZE)\n",
    "features = df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, _ = process_train_df(df, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 25))\n",
    "plt.matshow(df.corr(), fignum=fig.number)\n",
    "plt.xticks(range(df.shape[1]), df.columns, fontsize=18, rotation=90)\n",
    "plt.yticks(range(df.shape[1]), df.columns, fontsize=18)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=16)\n",
    "plt.title(\"Correlation matrix\", fontsize=20, y=-0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = df.sample(10000)\n",
    "# plt.figure(figsize=(16, 10))\n",
    "# plt.scatter(x=sample['speed_mean'], y=sample['speed_var'], alpha=0.5, c=sample.user, cmap='magma')\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from sklearn import svm\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(-5, 5, 500), np.linspace(-5, 5, 500))\n",
    "# Generate train data\n",
    "X = 0.3 * np.random.randn(100, 2)\n",
    "X_train = np.r_[X + 2, X - 2]\n",
    "# Generate some regular novel observations\n",
    "X = 0.3 * np.random.randn(20, 2)\n",
    "X_test = np.r_[X + 2, X - 2]\n",
    "# Generate some abnormal novel observations\n",
    "X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
    "\n",
    "# fit the model\n",
    "clf = svm.OneClassSVM(nu=0.05, kernel=\"rbf\", gamma=1)\n",
    "clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_pred_outliers = clf.predict(X_outliers)\n",
    "n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "n_error_test = y_pred_test[y_pred_test == -1].size\n",
    "n_error_outliers = y_pred_outliers[y_pred_outliers == 1].size\n",
    "\n",
    "# plot the line, the points, and the nearest vectors to the plane\n",
    "Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.title(\"Novelty Detection\")\n",
    "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap=plt.cm.PuBu)\n",
    "a = plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='darkred')\n",
    "plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors='palevioletred')\n",
    "\n",
    "s = 40\n",
    "b1 = plt.scatter(X_train[:, 0], X_train[:, 1], c='white', s=s, edgecolors='k')\n",
    "b2 = plt.scatter(X_test[:, 0], X_test[:, 1], c='blueviolet', s=s,\n",
    "                 edgecolors='k')\n",
    "c = plt.scatter(X_outliers[:, 0], X_outliers[:, 1], c='gold', s=s,\n",
    "                edgecolors='k')\n",
    "plt.axis('tight')\n",
    "plt.xlim((-5, 5))\n",
    "plt.ylim((-5, 5))\n",
    "plt.legend([a.collections[0], b1, b2, c],\n",
    "           [\"learned frontier\", \"training observations\",\n",
    "            \"new regular observations\", \"new abnormal observations\"],\n",
    "           loc=\"upper left\",\n",
    "           prop=matplotlib.font_manager.FontProperties(size=11))\n",
    "plt.xlabel(\n",
    "    \"error train: %d/200 ; errors novel regular: %d/40 ; \"\n",
    "    \"errors novel abnormal: %d/40\"\n",
    "    % (n_error_train, n_error_test, n_error_outliers))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = (df - df.min()) / (df.max() - df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20, 25))\n",
    "# plt.matshow(df.corr(), fignum=fig.number)\n",
    "# plt.xticks(range(df.shape[1]), df.columns, fontsize=18, rotation=90)\n",
    "# plt.yticks(range(df.shape[1]), df.columns, fontsize=18)\n",
    "# cb = plt.colorbar()\n",
    "# cb.ax.tick_params(labelsize=16)\n",
    "# plt.title(\"Correlation matrix\", fontsize=20, y=-0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = df.sample(1000)\n",
    "# plt.figure(figsize=(16, 10))\n",
    "# plt.scatter(x=sample['conn_level_mean'], y=sample['count_var'], alpha=0.5, c=sample.user, cmap='magma')\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for user in df.user.unique():\n",
    "#     for valid_user in df.user.unique():\n",
    "#         if user != valid_user:\n",
    "#             print('---------------------------------------------------------------------------')\n",
    "#             print('Valid user: ', valid_user, 'Extracted user: ', user)\n",
    "#             print('---------------------------------------------------------------------------')\n",
    "#             df1, df_ = extract_delayed_user(df.copy(), user)\n",
    "#             df1['user'] = 0\n",
    "#             df_ = split_users_into_two_classes(df_.copy(), valid_user)\n",
    "#             df_ = resample(df_)\n",
    "\n",
    "#             dataset = df_.to_numpy()\n",
    "#             X = dataset[:, :-1]\n",
    "#             y = dataset[:, -1]\n",
    "\n",
    "#             X_test = df1.to_numpy()[:, :-1]\n",
    "#             y_test = df1.to_numpy()[:, -1]\n",
    "            \n",
    "#             model = CatBoostClassifier(iterations=100, depth=6, loss_function='Logloss')\n",
    "#             model.fit(X, y, verbose=False)\n",
    "\n",
    "#             preds_class = model.predict(X_test)\n",
    "#             print('Accuracy: ', accuracy_score(preds_class, y_test))\n",
    "\n",
    "#             sum_ = 0\n",
    "#             imp = [ (x, i) for x, i in zip(model.feature_importances_, range(len(model.feature_importances_)) )]\n",
    "#             sorted_ = sorted(imp, key=lambda tup: tup[0])\n",
    "#             for i in range(len(sorted_)):\n",
    "#                 if sorted_[i][0] > 5:\n",
    "#                     print(sorted_[i][1], ': ', df_.columns[sorted_[i][1]], ' - ', sorted_[i][0])\n",
    "\n",
    "#             print('---------------------------------------------------------------------------')\n",
    "#             print('---------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in [VALIDATION_CATBOOST_BIG_DICT, VALIDATION_RFC_BIG_DICT, \\\n",
    "#           VALIDATION_SVC_BIG_DICT, VALIDATION_LR_BIG_DICT]:\n",
    "    \n",
    "#     for user, res in d.items():\n",
    "#         print(\"Valid User: \", user)\n",
    "#         print(\"--------------------------------------------------------------------------------\")\n",
    "#         means_acc = []\n",
    "#         means_prec = []\n",
    "#         means_rec = []\n",
    "#         means_roc = []\n",
    "#         means_f1 = []\n",
    "        \n",
    "#         for ex_user, ex_res in res.items():\n",
    "#             print('Ex user: ', ex_user)\n",
    "#             print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "#             y_true = ex_res['y_test']\n",
    "#             y_pred = ex_res['y_predict']\n",
    "#             if len(ex_res['y_proba'].shape) > 1 and ex_res['y_proba'].shape[1] > 1:\n",
    "#                 y_proba = ex_res['y_proba'][:, 1]\n",
    "#             else:\n",
    "#                 y_proba = ex_res['y_proba']\n",
    "                \n",
    "#             acc = accuracy_score(y_true, y_pred)\n",
    "#             prec = precision_score(y_true, y_pred)\n",
    "#             rec = recall_score(y_true, y_pred)\n",
    "#             f1 = f1_score(y_true, y_pred)\n",
    "            \n",
    "#             means_acc.append(acc)\n",
    "#             means_prec.append(prec)\n",
    "#             means_rec.append(rec)\n",
    "#             means_f1.append(f1)\n",
    "\n",
    "#             print('Accuracy: ', acc)\n",
    "#             print('Precision: ', prec)\n",
    "#             print('Recall: ', rec)\n",
    "#             try:\n",
    "#                 roc = roc_auc_score(y_true, y_proba)\n",
    "#                 means_roc.append(roc)\n",
    "#                 print('ROC-AUC: ', roc)\n",
    "#             except Exception as e:\n",
    "#                 print('ROC-AUC: skip')\n",
    "#             print('F1: ', f1)\n",
    "#             print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "            \n",
    "#         print('Mean accuracy: ', sum(means_acc) / len(means_acc))\n",
    "#         print('mean Precision: ', sum(means_prec) / len(means_prec))\n",
    "#         print('mean Recall: ', sum(means_rec) / len(means_rec))\n",
    "#         if len(means_roc) > 0:\n",
    "#             print('mean ROC-AUC: ', sum(means_roc) / len(means_roc))\n",
    "#         print('mean F1: ', sum(means_f1) / len(means_f1))\n",
    "\n",
    "#         print(\"--------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_df_parts = []\n",
    "# for user in df.labels.unique():\n",
    "#     new_df = df[df.labels == user].sample(int(df[df.labels == user].shape[0] * 0.2)).copy()\n",
    "#     gs_df_parts.append(new_df)\n",
    "\n",
    "# df = pd.concat(gs_df_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = df.sample(10000)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "# scatter = ax.scatter(x=sample['disappeared_devices_count_mean_mad'], y=sample['jaccard_index_var_skew'], \\\n",
    "#                      alpha=0.5, c=sample.user, cmap='plasma')\n",
    "\n",
    "# # produce a legend with the unique colors from the scatter\n",
    "# plt.rcParams['legend.title_fontsize'] = 'x-large'\n",
    "# legend1 = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Users\", fontsize=14)\n",
    "# ax.add_artist(legend1)\n",
    "\n",
    "# plt.xlabel('MAD среднего числа исчезнувших устройств', fontsize=12)\n",
    "# plt.ylabel('Skew дисперсии расстояния Жаккара', fontsize=12)\n",
    "\n",
    "# plt.savefig('.\\\\after.png', dpi=500)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = 1\n",
    "# kernel = 'rbf'\n",
    "# degree = 1\n",
    "# gamma = 5\n",
    "\n",
    "# user = 8\n",
    "\n",
    "# df['labels'] = df['user']\n",
    "\n",
    "# df_ = resample(df.copy())\n",
    "# df_ = split_users_into_two_classes(df_.copy(), user)\n",
    "# df_ = resample(df_)\n",
    "    \n",
    "# df_.loc[df_.user == 0, 'user'] = -1\n",
    "    \n",
    "# df_ = df_.drop('labels', axis=1)\n",
    "    \n",
    "# model = SVC(C=C, kernel=kernel, degree=degree, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.colors import ListedColormap\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# from sklearn.gaussian_process.kernels import RBF\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# h = .02  # step size in the mesh\n",
    "\n",
    "# figure = plt.figure(figsize=(27, 9))\n",
    "# i = 1\n",
    "\n",
    "# ds = df_.to_numpy().copy()\n",
    "# np.random.shuffle(ds)\n",
    "\n",
    "# X = ds[:, :-1]\n",
    "# y = ds[:, -1]\n",
    "\n",
    "# X_train = X[:10000, [14, 31]]\n",
    "# y_train = y[:10000]\n",
    "\n",
    "# X_test = X[160000:, [14, 31]]\n",
    "# y_test = y[160000:]\n",
    "\n",
    "# x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "# y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "\n",
    "# xx, yy = np.meshgrid(\n",
    "#                     np.arange(x_min, x_max, h),\n",
    "#                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# cm = plt.cm.RdBu\n",
    "# cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "# ax = plt.subplot(1, 2, 1)\n",
    "# ax.set_title(\"Input data\")\n",
    "# ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "#                edgecolors='k')\n",
    "# ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "#             edgecolors='k')\n",
    "# ax.set_xlim(xx.min(), xx.max())\n",
    "# ax.set_ylim(yy.min(), yy.max())\n",
    "# ax.set_xticks(())\n",
    "# ax.set_yticks(())\n",
    "\n",
    "# ax = plt.subplot(1, 1 + 1, 1)\n",
    "# model.fit(X_train, y_train)\n",
    "# score = model.score(X_test, y_test)\n",
    "\n",
    "# if hasattr(model, \"decision_function\"):\n",
    "#     Z = model.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "# else:\n",
    "#     Z = model.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "# Z = Z.reshape(xx.shape)\n",
    "# ax.contourf(xx, yy, Z, cmap=cm, alpha=.4)\n",
    "\n",
    "# ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "#                    edgecolors='k')\n",
    "# ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,\n",
    "#                    edgecolors='k', alpha=0.6)\n",
    "\n",
    "# ax.set_xlim(xx.min(), xx.max())\n",
    "# ax.set_ylim(yy.min(), yy.max())\n",
    "# ax.set_xticks(())\n",
    "# ax.set_yticks(())\n",
    "# # ax.set_title(name)\n",
    "# ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "#                 size=15, horizontalalignment='right')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr, tpr, threshold = roc_curve(y_true, y_proba)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# plt.title('ROC-curve')\n",
    "# plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "# plt.legend(loc = 'lower right')\n",
    "# plt.plot([0, 1], [0, 1],'r--')\n",
    "# plt.xlim([0, 1])\n",
    "# plt.ylim([0, 1])\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.savefig(\"..\\\\\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
