{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "from scipy.spatial import distance\n",
    "import scipy.stats as stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_SAMPLE_FREQ = '60s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\".\\\\_events\\\\_generated\\\\valid_user_3\\\\base_bt_0.data\", sep=';', index_col = False, header = None, low_memory = False, \\\n",
    "                 names = ['timestamp', 'action', 'bssid', 'major_class', 'class', \\\n",
    "                          'bond_state', 'type', 'user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>action</th>\n",
       "      <th>bssid</th>\n",
       "      <th>major_class</th>\n",
       "      <th>class</th>\n",
       "      <th>bond_state</th>\n",
       "      <th>type</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-13 20:12:13.128</td>\n",
       "      <td>android.bluetooth.device.action.FOUND</td>\n",
       "      <td>59:2D:94:4A:2D:D9</td>\n",
       "      <td>7936</td>\n",
       "      <td>7936</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-13 20:12:14.074</td>\n",
       "      <td>android.bluetooth.device.action.FOUND</td>\n",
       "      <td>EC:3C:BB:1E:E6:8B</td>\n",
       "      <td>512</td>\n",
       "      <td>524</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-13 20:12:14.124</td>\n",
       "      <td>android.bluetooth.device.action.FOUND</td>\n",
       "      <td>EC:3C:BB:1E:E6:8B</td>\n",
       "      <td>512</td>\n",
       "      <td>524</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-13 20:12:14.415</td>\n",
       "      <td>android.bluetooth.device.action.FOUND</td>\n",
       "      <td>40:34:C6:14:A9:58</td>\n",
       "      <td>7936</td>\n",
       "      <td>7936</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-13 20:12:14.482</td>\n",
       "      <td>android.bluetooth.device.action.FOUND</td>\n",
       "      <td>4B:91:A2:D9:FF:D7</td>\n",
       "      <td>7936</td>\n",
       "      <td>7936</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp                                 action  \\\n",
       "0  2021-03-13 20:12:13.128  android.bluetooth.device.action.FOUND   \n",
       "1  2021-03-13 20:12:14.074  android.bluetooth.device.action.FOUND   \n",
       "2  2021-03-13 20:12:14.124  android.bluetooth.device.action.FOUND   \n",
       "3  2021-03-13 20:12:14.415  android.bluetooth.device.action.FOUND   \n",
       "4  2021-03-13 20:12:14.482  android.bluetooth.device.action.FOUND   \n",
       "\n",
       "               bssid  major_class  class  bond_state  type  user  \n",
       "0  59:2D:94:4A:2D:D9         7936   7936          10     2     3  \n",
       "1  EC:3C:BB:1E:E6:8B          512    524          10     1     3  \n",
       "2  EC:3C:BB:1E:E6:8B          512    524          10     1     3  \n",
       "3  40:34:C6:14:A9:58         7936   7936          10     2     3  \n",
       "4  4B:91:A2:D9:FF:D7         7936   7936          10     2     3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 263 entries, 0 to 262\n",
      "Data columns (total 8 columns):\n",
      "timestamp      263 non-null object\n",
      "action         263 non-null object\n",
      "bssid          263 non-null object\n",
      "major_class    263 non-null int64\n",
      "class          263 non-null int64\n",
      "bond_state     263 non-null int64\n",
      "type           263 non-null int64\n",
      "user           263 non-null int64\n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 16.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['action'] == 'android.bluetooth.device.action.FOUND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.DatetimeIndex(df.timestamp)\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_USER = df.iloc[0]['user']\n",
    "df['events_count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['timestamp', 'action', 'class', 'major_class', 'bond_state', 'type'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bssid_map = { bssid.replace(' ', ''): idx for bssid, idx in zip(df.bssid.unique(), range(len(df.bssid.unique()))) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bssid = df.bssid.apply(lambda x: str(x).replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_string_join(col):\n",
    "    col = col.apply(lambda x: str(x))\n",
    "    return col.str.cat(sep = ',').replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_bssid_col(col):\n",
    "    array_len = len(bssid_map)\n",
    "    array = np.zeros(array_len, dtype = 'int8')\n",
    "    def fill_array(bssid):\n",
    "        array[bssid_map[bssid.replace(' ', '')]] = 1\n",
    "        return\n",
    "        \n",
    "    col.apply(lambda x: fill_array(x))\n",
    "    return np.array2string(array, separator = ',').replace(' ', '')[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_columns_count = 0\n",
    "for col in df.columns:\n",
    "    if col.find('one_hot') != -1:\n",
    "        one_hot_columns_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_agg(col):\n",
    "    if (col == VALID_USER).all():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = df.columns[1:1 + one_hot_columns_count]\n",
    "cat_columns_map = { col: 'mean' for col in cat_columns }\n",
    "\n",
    "all_func_dicts_quantum = { 'bssid' : agg_bssid_col, 'count' : 'sum', 'user' : user_agg, 'events_count' : 'sum' }\n",
    "all_func_dicts_quantum.update(cat_columns_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum = df.groupby(pd.Grouper(freq = '5s'), as_index=True).agg(all_func_dicts_quantum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum = df_quantum.reset_index()\n",
    "df_quantum.index = pd.DatetimeIndex(df_quantum.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum = df_quantum.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py:702: UserWarning: Duplicate names specified. This will raise an error in the future.\n",
      "  return _read(filepath_or_buffer, kwds)\n"
     ]
    }
   ],
   "source": [
    "df_le = pd.read_csv(\".\\\\_events\\\\_generated\\\\valid_user_3\\\\le_bt_3.data\", sep = ';', index_col = False, header = None, low_memory = False, \\\n",
    "                 names = ['timestamp', '1', '2', '3', 'level', '3', 'connectable', '4'])\n",
    "\n",
    "df_le = df_le.drop(df_le.columns.difference(['connectable','timestamp', 'level']), axis = 1)\n",
    "df_le.index = pd.DatetimeIndex(df_le.timestamp)\n",
    "df_le = df_le.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_le['connectable'] = df_le['connectable'].apply(lambda x: 1 if str(x).lower() == 'true' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_le = df_le.groupby(pd.Grouper(freq = '5s'), as_index=True).agg({'level':'mean', 'connectable':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_le = df_le.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_le_conn_status_from_row(row):\n",
    "    conn = df_le.iloc[df_le.index.get_loc(row.name, method = 'nearest')]['connectable']\n",
    "    time = df_le.iloc[df_le.index.get_loc(row.name, method = 'nearest')].name\n",
    "    return conn if abs((time - row.name).total_seconds()) < 10 else 0\n",
    "\n",
    "def get_le_level_from_row(row):\n",
    "    level = df_le.iloc[df_le.index.get_loc(row.name, method = 'nearest')]['level']\n",
    "    time = df_le.iloc[df_le.index.get_loc(row.name, method = 'nearest')].name\n",
    "    return level if abs((time - row.name).total_seconds()) < 10 else 0\n",
    "\n",
    "\n",
    "df_quantum['le_connectable'] = df_quantum.apply(lambda row: get_le_conn_status_from_row(row), axis = 1)\n",
    "df_quantum['le_level'] = df_quantum.apply(lambda row: get_le_level_from_row(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2array(string):\n",
    "    try:\n",
    "        array = np.fromstring(string, sep=',')\n",
    "        return array\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def to_ones_array(array):\n",
    "    try:\n",
    "        array[array != 0] = 1\n",
    "        return array\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_len(obj):\n",
    "    try:\n",
    "        length = len(obj)\n",
    "        return length\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occured_nets_count(row, prev_col, curr_col):\n",
    "    prev = to_ones_array(string2array(row[prev_col]))\n",
    "    curr = to_ones_array(string2array(row[curr_col]))\n",
    "    intersection = np.logical_and(curr, prev)\n",
    "    diff = np.logical_and(curr, np.logical_not(intersection))\n",
    "    \n",
    "    if (np.count_nonzero(np.logical_or(prev, curr)) == 0):\n",
    "        return 0\n",
    "    \n",
    "    return np.count_nonzero(diff) / np.count_nonzero(np.logical_or(prev, curr))\n",
    "\n",
    "def get_disappeared_nets_count(row, prev_col, curr_col):\n",
    "    prev = to_ones_array(string2array(row[prev_col]))\n",
    "    curr = to_ones_array(string2array(row[curr_col]))\n",
    "    intersection = np.logical_and(curr, prev)\n",
    "    diff = np.logical_and(prev, np.logical_not(intersection))\n",
    "    \n",
    "    if (np.count_nonzero(np.logical_or(prev, curr)) == 0):\n",
    "        return 0\n",
    "    \n",
    "    return np.count_nonzero(diff) / np.count_nonzero(np.logical_or(prev, curr))\n",
    "\n",
    "def get_jaccard_index(row, prev_col, curr_col):\n",
    "    prev = to_ones_array(string2array(row[prev_col]))\n",
    "    curr = to_ones_array(string2array(row[curr_col]))\n",
    "    return distance.jaccard(prev, curr)\n",
    "\n",
    "def get_occur_speed(row, prev_col, curr_col):\n",
    "    prev = to_ones_array(string2array(row[prev_col]))\n",
    "    curr = to_ones_array(string2array(row[curr_col]))\n",
    "    return np.linalg.norm(prev - curr) / np.sqrt(get_len(prev))\n",
    "\n",
    "def calc_single_cols_in_window(df, col, new_col, window, func):\n",
    "    def func_wrapper(func, row, prev_col, curr_col):\n",
    "        delta = row.timestamp - row.prev_timestamp\n",
    "        if pd.isnull(delta):\n",
    "            delta = 0\n",
    "        else:\n",
    "            delta = abs(delta.total_seconds())\n",
    "        if delta > 10 * 60:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return func(row, prev_col_name, col)\n",
    "        \n",
    "    new_cols = []\n",
    "        \n",
    "    for i in range(window):\n",
    "        prev_col_name = \"_\".join(['prev', col, str(i + 1)])\n",
    "        new_col_name = \"_\".join([new_col, str(i + 1)])\n",
    "        \n",
    "        df.loc[:, 'prev_timestamp'] = df.timestamp.shift(i + 1)\n",
    "        df.loc[:, prev_col_name] = df[col].shift(i + 1)\n",
    "        df.loc[:, new_col_name] = df.apply(lambda row: func_wrapper(func, row, prev_col_name, col), axis = 1)\n",
    "        df = df.drop(prev_col_name, axis = 1)\n",
    "        df = df.drop('prev_timestamp', axis = 1)\n",
    "        new_cols.append(new_col_name)\n",
    "        \n",
    "    df.loc[:, \"_\".join([new_col, 'mean'])] = df[new_cols].mean(axis = 1)\n",
    "    df.loc[:, \"_\".join([new_col, 'median'])] = df[new_cols].median(axis = 1)\n",
    "    df.loc[:, \"_\".join([new_col, 'var'])] = df[new_cols].var(axis = 1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 5\n",
    "\n",
    "occur_and_level_columns_map = [\n",
    "    (\"bssid\", \"occured_devices_count\", WINDOW_SIZE, get_occured_nets_count),\n",
    "    (\"bssid\", \"disappeared_devices_count\", WINDOW_SIZE, get_disappeared_nets_count),\n",
    "    (\"bssid\", \"jaccard_index\", WINDOW_SIZE, get_jaccard_index), \n",
    "    (\"bssid\", \"occur_speed\", WINDOW_SIZE, get_occur_speed)\n",
    "]\n",
    "\n",
    "for (col, new_col, window, func) in occur_and_level_columns_map:\n",
    "    df_quantum = calc_single_cols_in_window(df_quantum, col, new_col, window, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn_level_speed(row, prev_col, curr_col):\n",
    "    return row[curr_col] - row[prev_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_columns_map = [\n",
    "    (\"count\", \"count_speed\", WINDOW_SIZE, get_conn_level_speed)\n",
    "]\n",
    "\n",
    "for (col, new_col, window, func) in single_columns_map:\n",
    "    df_quantum = calc_single_cols_in_window(df_quantum, col, new_col, window, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_str(col):\n",
    "    all_freq = col.str.cat(sep=',')\n",
    "    return string2array(all_freq)\n",
    "\n",
    "def str_mean(col):\n",
    "    return np.mean(agg_str(col))\n",
    "\n",
    "def str_var(col):\n",
    "    return np.var(agg_str(col))\n",
    "\n",
    "def str_median(col):\n",
    "    return np.median(agg_str(col))\n",
    "\n",
    "def str_skew(col):\n",
    "    return stats.skew(agg_str(col))\n",
    "\n",
    "def str_kurt(col):\n",
    "    return stats.kurtosis(agg_str(col))\n",
    "\n",
    "def mean(col):\n",
    "    return np.mean(col)\n",
    "\n",
    "def var(col):\n",
    "    return np.var(col)\n",
    "\n",
    "def median(col):\n",
    "    return np.median(col)\n",
    "\n",
    "def skew(col):\n",
    "    return stats.skew(col)\n",
    "\n",
    "def kurt(col):\n",
    "    return stats.kurtosis(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_drop = []\n",
    "names = [\n",
    "    \"occured_devices_count\",\n",
    "    \"disappeared_devices_count\",\n",
    "    \"jaccard_index\",\n",
    "    \"occur_speed\",\n",
    "    \"count_speed\"\n",
    "]\n",
    "\n",
    "for i in range(1, WINDOW_SIZE + 1):\n",
    "    for name in names:\n",
    "        cols_for_drop.append('_'.join([name, str(i)]))\n",
    "        \n",
    "df_quantum = df_quantum.drop(['bssid', 'timestamp'], axis = 1)\n",
    "df_quantum = df_quantum.drop(cols_for_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['count', 'user', 'events_count', 'le_connectable', 'le_level',\n",
       "       'occured_devices_count_mean', 'occured_devices_count_median',\n",
       "       'occured_devices_count_var', 'disappeared_devices_count_mean',\n",
       "       'disappeared_devices_count_median', 'disappeared_devices_count_var',\n",
       "       'jaccard_index_mean', 'jaccard_index_median', 'jaccard_index_var',\n",
       "       'occur_speed_mean', 'occur_speed_median', 'occur_speed_var',\n",
       "       'count_speed_mean', 'count_speed_median', 'count_speed_var'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quantum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_agg(col):\n",
    "    if (col == 1).all():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols = [x for x in df_quantum.columns[:one_hot_columns_count + 3] if x != 'user' and x != 'events_count']\n",
    "speed_acc_cols = df_quantum.columns[one_hot_columns_count + 3:]\n",
    "\n",
    "common_funcs_list = [mean, var, median, skew, kurt]\n",
    "special_funcs_list = [mean, pd.DataFrame.mad, skew]\n",
    "\n",
    "common_cols_map = { col : common_funcs_list for col in common_cols }\n",
    "speed_acc_cols_map = { col : special_funcs_list for col in speed_acc_cols }\n",
    "\n",
    "additional = { 'user' : user_agg, 'events_count' : 'sum' }\n",
    "\n",
    "agg_dict = common_cols_map\n",
    "agg_dict.update(speed_acc_cols_map)\n",
    "agg_dict.update(additional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum[speed_acc_cols] = df_quantum[speed_acc_cols].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampling = df_quantum.groupby(pd.Grouper(freq = TIME_SAMPLE_FREQ)).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolling = df_quantum.rolling(TIME_SAMPLE_FREQ, min_periods = 1, center = False).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampling.columns = [\"_\".join([str(high_level_name), str(low_level_name)]) \\\n",
    "                       for (high_level_name, low_level_name) in df_sampling.columns.values]\n",
    "\n",
    "df_rolling.columns = [\"_\".join([str(high_level_name), str(low_level_name)]) \\\n",
    "                      for (high_level_name, low_level_name) in df_rolling.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_quantum['user'] == 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampling = df_sampling.dropna()\n",
    "df_sampling = df_sampling.fillna(0)\n",
    "\n",
    "df_rolling = df_rolling.dropna()\n",
    "df_rolling = df_rolling.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\_datasets\\\\60s\\\\bt_sampling_dataset_3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-5117a7b5777d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_sampling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\\\\_datasets\\\\60s\\\\bt_sampling_dataset_3.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_rolling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\\\\_datasets\\\\60s\\\\bt_rolling_dataset_3.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3018\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3019\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 3020\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    156\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    158\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\_datasets\\\\60s\\\\bt_sampling_dataset_3.csv'"
     ]
    }
   ],
   "source": [
    "df_sampling.to_csv(\".\\\\_datasets\\\\60s\\\\bt_sampling_dataset_3.csv\")\n",
    "df_rolling.to_csv(\".\\\\_datasets\\\\60s\\\\bt_rolling_dataset_3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
