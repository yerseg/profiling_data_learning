{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, plot_roc_curve, make_scorer, f1_score, roc_auc_score, det_curve\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate, LeaveOneGroupOut, PredefinedSplit, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "import json\n",
    "from datetime import datetime as dt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dict(d, u):\n",
    "    import collections.abc\n",
    "    for k, v in u.items():\n",
    "        if isinstance(v, collections.abc.Mapping):\n",
    "            d[k] = update(d.get(k, {}), v)\n",
    "        else:\n",
    "            d[k] = v\n",
    "    return d\n",
    "\n",
    "\n",
    "def update_file_with_results(file_path, results_dict):\n",
    "    with open(file_path, 'r') as f:\n",
    "        res = json.load(f)\n",
    "    \n",
    "    res = update_dict(res, results_dict)\n",
    "    \n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(res, f, sort_keys=True, indent=2)\n",
    "        \n",
    "        \n",
    "def get_dict_with_results(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        res = json.load(f)\n",
    "    return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eer(fpr, fnr, thresholds):\n",
    "    idx = np.nanargmin(np.absolute((fnr - fpr)))\n",
    "    eer_threshold = thresholds[idx]\n",
    "    eer1 = fpr[idx]\n",
    "    \n",
    "    return eer1, eer_threshold\n",
    "\n",
    "\n",
    "def auc_roc(fpr, tpr):\n",
    "    return metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "def confusion_matrix_thr(y_true, proba, threshold):\n",
    "    predict = proba\n",
    "    predict[predict > threshold] = 1\n",
    "    predict[predict <= threshold] = 0\n",
    "    \n",
    "    matr = metrics.confusion_matrix(y_true, predict, labels=[0, 1])\n",
    "    \n",
    "    tp = matr[0, 0]\n",
    "    fp = matr[1, 0]\n",
    "    fn = matr[0, 1]\n",
    "    tn = matr[1, 1]\n",
    "    \n",
    "    return tn, fp, fn, tp\n",
    "\n",
    "\n",
    "def calc_metrics(y_test, proba, thresholds):\n",
    "    FPR = np.array([])\n",
    "    TPR = np.array([])\n",
    "    FNR = np.array([])\n",
    "    F_score = np.array([])\n",
    "    ANGA = np.array([])\n",
    "    ANIA = np.array([])\n",
    "\n",
    "    for thr in thresholds:\n",
    "        tn, fp, fn, tp = confusion_matrix_thr(y_test, proba.copy(), thr)\n",
    "        \n",
    "        fpr = fp / (tn + fp)\n",
    "        tpr = tp / (tp + fn)\n",
    "        fnr = fn / (tp + fn)\n",
    "        \n",
    "        FPR = np.append(FPR, 1 if np.isnan(fpr) else fpr)\n",
    "        TPR = np.append(TPR, 1 if np.isnan(tpr) else tpr)\n",
    "        FNR = np.append(FNR, 1 if np.isnan(fnr) else fnr)\n",
    "        F_score = np.append(F_score, tp / (tp + 0.5 * (fn + fp)))\n",
    "    \n",
    "    EER, EER_thr = eer(fpr=FPR, fnr=FNR, thresholds=thresholds)\n",
    "    AUC_ROC = auc_roc(fpr=FPR, tpr=TPR)\n",
    "    \n",
    "    return {'FAR': FPR, \n",
    "            'FRR': FNR, \n",
    "            'F': F_score, \n",
    "            'EER': EER, \n",
    "            'EER_thr': EER_thr, \n",
    "            'AUC-ROC': AUC_ROC}\n",
    "\n",
    "\n",
    "def iterate_over_cv_results(results):\n",
    "    for df_type, inner in results.items():\n",
    "        if df_type == 'stub':\n",
    "            continue\n",
    "\n",
    "        for window_type, inner1 in inner.items():\n",
    "            for window_size, inner2 in inner1.items():\n",
    "                for model, inner3 in inner2.items():\n",
    "                    for valid_user, inner4 in inner3['cross_validation']['valid_user'].items():\n",
    "                        yield {'df_type': df_type, \n",
    "                               'window_type': window_type, \n",
    "                               'window_size': window_size, \n",
    "                               'model': model, \n",
    "                               'valid_user': valid_user, \n",
    "                               'accuracy': np.array(inner4['accuracy'])}\n",
    "\n",
    "                        \n",
    "def iterate_over_final_results(results):\n",
    "    for df_type, inner in results.items():\n",
    "        if df_type == 'stub':\n",
    "            continue\n",
    "\n",
    "        for window_type, inner1 in inner.items():\n",
    "            for window_size, inner2 in inner1.items():\n",
    "                for model, inner3 in inner2.items():\n",
    "                    for valid_user, inner4 in inner3['final_validation']['valid_user'].items():\n",
    "                        for intruder, inner5 in inner4['extracted_user'].items(): \n",
    "                            yield {'df_type': df_type, \n",
    "                                   'window_type': window_type, \n",
    "                                   'window_size': window_size, \n",
    "                                   'model': model, \n",
    "                                   'valid_user': valid_user, \n",
    "                                   'intruder': intruder,\n",
    "                                   'test': np.array(inner5['test']), \n",
    "                                   'proba': np.array(inner5['proba'])[:, 1], \n",
    "                                   'time': [] if 'time' not in inner5.keys() else np.array(inner5['time'])}\n",
    "            \n",
    "\n",
    "def avg_accuracy(results):\n",
    "    metrics = {}\n",
    "    for res in iterate_over_cv_results(results):\n",
    "        key = (res['df_type'], res['window_type'], res['window_size'], res['model'])\n",
    "        if key not in metrics.keys():\n",
    "            metrics[key] = {'accuracy': []}\n",
    "        \n",
    "        metrics[key]['accuracy'].append(res['accuracy'])\n",
    "        \n",
    "    for k, v in metrics.items():\n",
    "        metrics[k] = ({'accuracy': np.array(v['accuracy']).mean()})    \n",
    "        \n",
    "    return metrics\n",
    "          \n",
    "    \n",
    "def avg_common_metrics(results, thresholds):\n",
    "    metrics = {}\n",
    "    for res in iterate_over_final_results(results):\n",
    "        key = (res['df_type'], res['window_type'], res['window_size'], res['model'])\n",
    "        if key not in metrics.keys():\n",
    "            metrics[key] = {'EER': [], 'AUC-ROC': []}\n",
    "        \n",
    "        metrics_dict = calc_metrics(res['test'], res['proba'], thresholds)\n",
    "        \n",
    "        metrics[key]['EER'].append(metrics_dict['EER'])\n",
    "        metrics[key]['AUC-ROC'].append(metrics_dict['AUC-ROC'])\n",
    "        \n",
    "    for k, v in metrics.items():\n",
    "        metrics[k] = ({'EER': np.array(v['EER']).mean(), \n",
    "                       'AUC-ROC': np.array(v['AUC-ROC']).mean()})\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_common_accuracy_tables(results, df_type, window_type, window_sizes):\n",
    "    word_document = Document()\n",
    "    document_name = '_'.join(['df_type', 'window_type'])\n",
    "    \n",
    "    table = word_document.add_table(rows=10, cols=6) # we add rows iteratively\n",
    "    table.style = 'TableGrid'\n",
    "    \n",
    "    NameIdx = 0\n",
    "    WndIdx = 1\n",
    "    CatBoostIdx = 2\n",
    "    RandomForestIdx = 3\n",
    "    SVCIdx = 4\n",
    "    LogRegIdx = 5\n",
    "    \n",
    "    def get_col_idx(model_tag):\n",
    "        if model_tag == 'CatBoost':\n",
    "            return CatBoostIdx\n",
    "        if model_tag == 'RandomForest':\n",
    "            return RandomForestIdx\n",
    "        if model_tag == 'SVC':\n",
    "            return SVCIdx\n",
    "        if model_tag == 'LogReg':\n",
    "            return LogRegIdx\n",
    "    \n",
    "    s5 = 1\n",
    "    s10 = 2\n",
    "    s30 = 3\n",
    "    s60 = 4\n",
    "    s90 = 5\n",
    "    s120 = 6\n",
    "    s240 = 7\n",
    "    s600 = 8\n",
    "    \n",
    "    def get_row_idx(wnd):\n",
    "        if wnd == '5s':\n",
    "            return s5\n",
    "        if wnd == '10s':\n",
    "            return s10\n",
    "        if wnd == '30s':\n",
    "            return s30\n",
    "        if wnd == '60s':\n",
    "            return s60\n",
    "        if wnd == '90s':\n",
    "            return s90\n",
    "        if wnd == '120s':\n",
    "            return s120\n",
    "        if wnd == '240s':\n",
    "            return s240\n",
    "        if wnd == '600s':\n",
    "            return s600\n",
    "    \n",
    "    table = add_columns_names(table, ['Метрика', 'Размер окна, с', 'CatBoostClassifier', 'RandomForest', 'SVM-SVC', 'LogisticRegression'])\n",
    "    table = add_rows_names(table, ['Метрика', 'Accuracy'])\n",
    "    table = add_rows_names(table, ['Размер окна, с'] + \n",
    "                           [str(x).replace('s', '') for x in window_sizes] + ['Лучший результат'], col_index=WndIdx)\n",
    "    \n",
    "    best_res = {}\n",
    "    for k, v in results.items():\n",
    "        if k[0] == df_type and k[1] == window_type:\n",
    "            accuracy = results[k]['accuracy']\n",
    "            \n",
    "            if k[3] not in best_res.keys():\n",
    "                best_res[k[3]] = ('0s', 0)\n",
    "            \n",
    "            if accuracy > best_res[k[3]][1]:\n",
    "                best_res[k[3]][0] = k[2]\n",
    "                best_res[k[3]][1] = accuracy\n",
    "            \n",
    "            table.rows[get_row_idx(k[2])].cells[get_col_idx(k[3])].text = str(accuracy)\n",
    "            \n",
    "    for k, v in best_res.items():\n",
    "        table.rows[get_row_idx(v[0])].cells[get_col_idx(k)].text = str(v[1])\n",
    "            \n",
    "    word_document.add_page_break()\n",
    "    word_document.save(document_name + '.docx')\n",
    "    \n",
    "    \n",
    "def generate_common_metrics_tables(results, df_type, window_type, window_sizes):\n",
    "   \n",
    "    NameIdx = 0\n",
    "    WndIdx = 1\n",
    "    CatBoostIdx = 2\n",
    "    RandomForestIdx = 3\n",
    "    SVCIdx = 4\n",
    "    LogRegIdx = 5\n",
    "    \n",
    "    def get_col_idx(model_tag):\n",
    "        if model_tag == 'CatBoost':\n",
    "            return CatBoostIdx\n",
    "        if model_tag == 'RandomForest':\n",
    "            return RandomForestIdx\n",
    "        if model_tag == 'SVC':\n",
    "            return SVCIdx\n",
    "        if model_tag == 'LogReg':\n",
    "            return LogRegIdx\n",
    "    \n",
    "    s5 = 1\n",
    "    s10 = 2\n",
    "    s30 = 3\n",
    "    s60 = 4\n",
    "    s90 = 5\n",
    "    s120 = 6\n",
    "    s240 = 7\n",
    "    s600 = 8\n",
    "    \n",
    "    def get_row_idx(wnd):\n",
    "        if wnd == '5s':\n",
    "            return s5\n",
    "        if wnd == '10s':\n",
    "            return s10\n",
    "        if wnd == '30s':\n",
    "            return s30\n",
    "        if wnd == '60s':\n",
    "            return s60\n",
    "        if wnd == '90s':\n",
    "            return s90\n",
    "        if wnd == '120s':\n",
    "            return s120\n",
    "        if wnd == '240s':\n",
    "            return s240\n",
    "        if wnd == '600s':\n",
    "            return s600\n",
    "        \n",
    "    for metr in ['AUC-ROC', 'EER']:\n",
    "        \n",
    "        word_document = Document()\n",
    "        document_name = '_'.join(['df_type', 'window_type', metr])\n",
    "\n",
    "        table = word_document.add_table(rows=10, cols=6) # we add rows iteratively\n",
    "        table.style = 'TableGrid'\n",
    "        \n",
    "        table = add_columns_names(table, ['Метрика', 'Размер окна, с', 'CatBoostClassifier', 'RandomForest', 'SVM-SVC', 'LogisticRegression'])\n",
    "        table = add_rows_names(table, ['Метрика', metr])\n",
    "        table = add_rows_names(table, ['Размер окна, с'] + \n",
    "                               [str(x).replace('s', '') for x in window_sizes] + ['Лучший результат'], col_index=WndIdx)\n",
    "\n",
    "        best_res = {}\n",
    "        for k, v in results.items():\n",
    "            if k[0] == df_type and k[1] == window_type:\n",
    "                accuracy = results[k][metr]\n",
    "\n",
    "                if k[3] not in best_res.keys():\n",
    "                    best_res[k[3]] = ('0s', 0)\n",
    "\n",
    "                if accuracy > best_res[k[3]][1]:\n",
    "                    best_res[k[3]][0] = k[2]\n",
    "                    best_res[k[3]][1] = accuracy\n",
    "\n",
    "                table.rows[get_row_idx(k[2])].cells[get_col_idx(k[3])].text = str(accuracy)\n",
    "\n",
    "        for k, v in best_res.items():\n",
    "            table.rows[get_row_idx(v[0])].cells[get_col_idx(k)].text = str(v[1])\n",
    "\n",
    "        word_document.add_page_break()\n",
    "        word_document.save(document_name + '.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = \".\\\\_results\"\n",
    "RESULTS_FILE = 'bt_results.json'\n",
    "\n",
    "THRESHOLDS = np.arange(0.0, 1.01, 0.05)\n",
    "\n",
    "results = get_dict_with_results(os.path.join(RESULTS_PATH, RESULTS_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('bt', 'rolling', '60s', 'CatBoost'): {'accuracy': 0.8964166017861801},\n",
       " ('bt', 'rolling', '60s', 'LogReg'): {'accuracy': 0.9210366240796924},\n",
       " ('bt', 'rolling', '60s', 'RandomForest'): {'accuracy': 0.8741074958134654},\n",
       " ('bt', 'sampling', '60s', 'CatBoost'): {'accuracy': 0.9025587289930687},\n",
       " ('bt', 'sampling', '60s', 'LogReg'): {'accuracy': 0.9292526772441232},\n",
       " ('bt', 'sampling', '60s', 'RandomForest'): {'accuracy': 0.8830167486596852}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracy(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('bt', 'rolling', '60s', 'CatBoost'): {'EER': 0.2415056009300803,\n",
       "  'AUC-ROC': 0.8627148197291062},\n",
       " ('bt', 'rolling', '60s', 'LogReg'): {'EER': 0.4282943184161751,\n",
       "  'AUC-ROC': 0.7188691617094093},\n",
       " ('bt', 'rolling', '60s', 'RandomForest'): {'EER': 0.12824692365706278,\n",
       "  'AUC-ROC': 0.9162911549937582},\n",
       " ('bt', 'sampling', '60s', 'CatBoost'): {'EER': 0.1995506944816863,\n",
       "  'AUC-ROC': 0.8191199189993269},\n",
       " ('bt', 'sampling', '60s', 'LogReg'): {'EER': 0.19195174384218738,\n",
       "  'AUC-ROC': 0.7170741268418472},\n",
       " ('bt', 'sampling', '60s', 'RandomForest'): {'EER': 0.22613470664120547,\n",
       "  'AUC-ROC': 0.8154799261677675}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_common_metrics(results, THRESHOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_TYPES = ['rolling', 'sampling']\n",
    "WINDOWS = ['5s', '10s', '30s', '60s', '90s', '120s', '240s', '600s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
