{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "from scipy.spatial import distance\n",
    "import scipy.stats as stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_SAMPLE_FREQ = '5s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\".\\\\_generated\\\\bt_3.data\", index_col = False, header = None, low_memory = False, \\\n",
    "                 names = ['timestamp', 'ssid', 'bssid', 'major_class', 'class', \\\n",
    "                          'bond_state', 'type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ssid</th>\n",
       "      <th>bssid</th>\n",
       "      <th>major_class</th>\n",
       "      <th>class</th>\n",
       "      <th>bond_state</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07.12.2020_08:44:43.812</td>\n",
       "      <td>RK-G202S</td>\n",
       "      <td>EE:3B:81:FA:6C:BA</td>\n",
       "      <td>7936</td>\n",
       "      <td>7936</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07.12.2020_08:44:43.870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75:D8:01:21:BE:16</td>\n",
       "      <td>7936</td>\n",
       "      <td>7936</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>07.12.2020_08:44:43.948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49:FE:6A:CD:94:48</td>\n",
       "      <td>7936</td>\n",
       "      <td>7936</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07.12.2020_08:44:44.824</td>\n",
       "      <td>Redmi</td>\n",
       "      <td>04:D1:3A:E5:09:95</td>\n",
       "      <td>512</td>\n",
       "      <td>524</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.12.2020_14:39:22.792</td>\n",
       "      <td>RK-G202S</td>\n",
       "      <td>EE:3B:81:FA:6C:BA</td>\n",
       "      <td>7936</td>\n",
       "      <td>7936</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp      ssid              bssid  major_class  class  \\\n",
       "0  07.12.2020_08:44:43.812  RK-G202S  EE:3B:81:FA:6C:BA         7936   7936   \n",
       "1  07.12.2020_08:44:43.870       NaN  75:D8:01:21:BE:16         7936   7936   \n",
       "2  07.12.2020_08:44:43.948       NaN  49:FE:6A:CD:94:48         7936   7936   \n",
       "3  07.12.2020_08:44:44.824     Redmi  04:D1:3A:E5:09:95          512    524   \n",
       "4  10.12.2020_14:39:22.792  RK-G202S  EE:3B:81:FA:6C:BA         7936   7936   \n",
       "\n",
       "   bond_state  type  \n",
       "0          10     2  \n",
       "1          10     2  \n",
       "2          10     2  \n",
       "3          10     1  \n",
       "4          10     2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120347 entries, 0 to 120346\n",
      "Data columns (total 7 columns):\n",
      "timestamp      120347 non-null object\n",
      "ssid           48942 non-null object\n",
      "bssid          120347 non-null object\n",
      "major_class    120347 non-null int64\n",
      "class          120347 non-null int64\n",
      "bond_state     120347 non-null int64\n",
      "type           120347 non-null int64\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = df['timestamp'].apply(lambda x: dt.strptime(x, '%d.%m.%Y_%H:%M:%S.%f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_maj_class = pd.get_dummies(df['major_class'], prefix='one_hot_c')\n",
    "df = df.join(one_hot_maj_class)\n",
    "\n",
    "one_hot_bond = pd.get_dummies(df['bond_state'], prefix='one_hot_b')\n",
    "df = df.join(one_hot_bond)\n",
    "\n",
    "one_hot_type = pd.get_dummies(df['type'], prefix='one_hot_t')\n",
    "df = df.join(one_hot_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.DatetimeIndex(df.timestamp)\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['timestamp', 'ssid', 'class', 'major_class', 'bond_state', 'type'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bssid_map = { bssid.replace(' ', ''): idx for bssid, idx in zip(df.bssid.unique(), range(len(df.bssid.unique()))) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bssid = df.bssid.apply(lambda x: str(x).replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_string_join(col):\n",
    "    col = col.apply(lambda x: str(x))\n",
    "    return col.str.cat(sep = ',').replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_bssid_col(col):\n",
    "    array_len = len(bssid_map)\n",
    "    array = np.zeros(array_len, dtype = 'int8')\n",
    "    def fill_array(bssid):\n",
    "        array[bssid_map[bssid.replace(' ', '')]] = 1\n",
    "        return\n",
    "        \n",
    "    col.apply(lambda x: fill_array(x))\n",
    "    return np.array2string(array, separator = ',').replace(' ', '')[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_columns_count = 0\n",
    "for col in df.columns:\n",
    "    if col.find('one_hot') != -1:\n",
    "        one_hot_columns_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = df.columns[1:1 + one_hot_columns_count]\n",
    "cat_columns_map = { col: 'mean' for col in cat_columns }\n",
    "\n",
    "all_func_dicts_quantum = { 'bssid' : agg_bssid_col, 'count' : 'sum' }\n",
    "all_func_dicts_quantum.update(cat_columns_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum = df.groupby(pd.Grouper(freq = '5s'), as_index=True).agg(all_func_dicts_quantum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum = df_quantum.reset_index()\n",
    "df_quantum.index = pd.DatetimeIndex(df_quantum.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum = df_quantum.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_le = pd.read_csv(\".\\\\_generated\\\\le_bt_3.data\", index_col = False, header = None, low_memory = False, \\\n",
    "                 names = ['timestamp', 'stamp', '1', '2', 'level', '3', 'connectable', '8'])\n",
    "\n",
    "df_le = df_le.drop(df_le.columns.difference(['connectable','timestamp', 'level']), axis = 1)\n",
    "df_le['timestamp'] = df_le['timestamp'].apply(lambda x: dt.strptime(x, '%d.%m.%Y_%H:%M:%S.%f'))\n",
    "df_le.index = pd.DatetimeIndex(df_le.timestamp)\n",
    "df_le = df_le.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_le['connectable'] = df_le['connectable'].apply(lambda x: 1 if str(x).lower() == 'true' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_le = df_le.groupby(pd.Grouper(freq = '5s'), as_index=True).agg({'level':'mean', 'connectable':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_le = df_le.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_le_conn_status_from_row(row):\n",
    "    conn = df_le.iloc[df_le.index.get_loc(row.name, method = 'nearest')]['connectable']\n",
    "    time = df_le.iloc[df_le.index.get_loc(row.name, method = 'nearest')].name\n",
    "    return conn if abs((time - row.name).total_seconds()) < 10 else 0\n",
    "\n",
    "def get_le_level_from_row(row):\n",
    "    level = df_le.iloc[df_le.index.get_loc(row.name, method = 'nearest')]['level']\n",
    "    time = df_le.iloc[df_le.index.get_loc(row.name, method = 'nearest')].name\n",
    "    return level if abs((time - row.name).total_seconds()) < 10 else 0\n",
    "\n",
    "\n",
    "df_quantum['le_connectable'] = df_quantum.apply(lambda row: get_le_conn_status_from_row(row), axis = 1)\n",
    "df_quantum['le_level'] = df_quantum.apply(lambda row: get_le_level_from_row(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2array(string):\n",
    "    try:\n",
    "        array = np.fromstring(string, sep=',')\n",
    "        return array\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def to_ones_array(array):\n",
    "    try:\n",
    "        array[array != 0] = 1\n",
    "        return array\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_len(obj):\n",
    "    try:\n",
    "        length = len(obj)\n",
    "        return length\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occured_nets_count(row, prev_col, curr_col):\n",
    "    prev = to_ones_array(string2array(row[prev_col]))\n",
    "    curr = to_ones_array(string2array(row[curr_col]))\n",
    "    intersection = np.logical_and(curr, prev)\n",
    "    diff = np.logical_and(curr, np.logical_not(intersection))\n",
    "    \n",
    "    if (np.count_nonzero(np.logical_or(prev, curr)) == 0):\n",
    "        return 0\n",
    "    \n",
    "    return np.count_nonzero(diff) / np.count_nonzero(np.logical_or(prev, curr))\n",
    "\n",
    "def get_disappeared_nets_count(row, prev_col, curr_col):\n",
    "    prev = to_ones_array(string2array(row[prev_col]))\n",
    "    curr = to_ones_array(string2array(row[curr_col]))\n",
    "    intersection = np.logical_and(curr, prev)\n",
    "    diff = np.logical_and(prev, np.logical_not(intersection))\n",
    "    \n",
    "    if (np.count_nonzero(np.logical_or(prev, curr)) == 0):\n",
    "        return 0\n",
    "    \n",
    "    return np.count_nonzero(diff) / np.count_nonzero(np.logical_or(prev, curr))\n",
    "\n",
    "def get_jaccard_index(row, prev_col, curr_col):\n",
    "    prev = to_ones_array(string2array(row[prev_col]))\n",
    "    curr = to_ones_array(string2array(row[curr_col]))\n",
    "    return distance.jaccard(prev, curr)\n",
    "\n",
    "def get_occur_speed(row, prev_col, curr_col):\n",
    "    prev = to_ones_array(string2array(row[prev_col]))\n",
    "    curr = to_ones_array(string2array(row[curr_col]))\n",
    "    return np.linalg.norm(prev - curr) / np.sqrt(get_len(prev))\n",
    "\n",
    "def calc_single_cols_in_window(df, col, new_col, window, func):\n",
    "    def func_wrapper(func, row, prev_col, curr_col):\n",
    "        delta = row.timestamp - row.prev_timestamp\n",
    "        if pd.isnull(delta):\n",
    "            delta = 0\n",
    "        else:\n",
    "            delta = abs(delta.total_seconds())\n",
    "        if delta > 10 * 60:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return func(row, prev_col_name, col)\n",
    "        \n",
    "    new_cols = []\n",
    "        \n",
    "    for i in range(window):\n",
    "        prev_col_name = \"_\".join(['prev', col, str(i + 1)])\n",
    "        new_col_name = \"_\".join([new_col, str(i + 1)])\n",
    "        \n",
    "        df.loc[:, 'prev_timestamp'] = df.timestamp.shift(i + 1)\n",
    "        df.loc[:, prev_col_name] = df[col].shift(i + 1)\n",
    "        df.loc[:, new_col_name] = df.apply(lambda row: func_wrapper(func, row, prev_col_name, col), axis = 1)\n",
    "        df = df.drop(prev_col_name, axis = 1)\n",
    "        df = df.drop('prev_timestamp', axis = 1)\n",
    "        new_cols.append(new_col_name)\n",
    "        \n",
    "    df.loc[:, \"_\".join([new_col, 'mean'])] = df[new_cols].mean(axis = 1)\n",
    "    df.loc[:, \"_\".join([new_col, 'median'])] = df[new_cols].median(axis = 1)\n",
    "    df.loc[:, \"_\".join([new_col, 'var'])] = df[new_cols].var(axis = 1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 3\n",
    "\n",
    "occur_and_level_columns_map = [\n",
    "    (\"bssid\", \"occured_devices_count\", WINDOW_SIZE, get_occured_nets_count),\n",
    "    (\"bssid\", \"disappeared_devices_count\", WINDOW_SIZE, get_disappeared_nets_count),\n",
    "    (\"bssid\", \"jaccard_index\", WINDOW_SIZE, get_jaccard_index), \n",
    "    (\"bssid\", \"occur_speed\", WINDOW_SIZE, get_occur_speed)\n",
    "]\n",
    "\n",
    "for (col, new_col, window, func) in occur_and_level_columns_map:\n",
    "    df_quantum = calc_single_cols_in_window(df_quantum, col, new_col, window, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn_level_speed(row, prev_col, curr_col):\n",
    "    return row[curr_col] - row[prev_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 3\n",
    "\n",
    "single_columns_map = [\n",
    "    (\"count\", \"count_speed\", WINDOW_SIZE, get_conn_level_speed)\n",
    "]\n",
    "\n",
    "for (col, new_col, window, func) in single_columns_map:\n",
    "    df_quantum = calc_single_cols_in_window(df_quantum, col, new_col, window, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acceleration(row, prev_col, curr_col):\n",
    "    return abs(row[curr_col] - row[prev_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 3\n",
    "\n",
    "multi_speed_cols = [\"occured_devices_count_mean\", \"jaccard_index_mean\", \"occur_speed_mean\", \"disappeared_devices_count_mean\", \n",
    "                    \"count_speed_mean\"]\n",
    "\n",
    "for col in multi_speed_cols:\n",
    "    df_quantum = calc_single_cols_in_window(df_quantum, col, \"_\".join([\"acceleration\", col]), window, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_str(col):\n",
    "    all_freq = col.str.cat(sep=',')\n",
    "    return string2array(all_freq)\n",
    "\n",
    "def str_mean(col):\n",
    "    return np.mean(agg_str(col))\n",
    "\n",
    "def str_var(col):\n",
    "    return np.var(agg_str(col))\n",
    "\n",
    "def str_median(col):\n",
    "    return np.median(agg_str(col))\n",
    "\n",
    "def str_skew(col):\n",
    "    return stats.skew(agg_str(col))\n",
    "\n",
    "def str_kurt(col):\n",
    "    return stats.kurtosis(agg_str(col))\n",
    "\n",
    "def mean(col):\n",
    "    return np.mean(col)\n",
    "\n",
    "def var(col):\n",
    "    return np.var(col)\n",
    "\n",
    "def median(col):\n",
    "    return np.median(col)\n",
    "\n",
    "def skew(col):\n",
    "    return stats.skew(col)\n",
    "\n",
    "def kurt(col):\n",
    "    return stats.kurtosis(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum = df_quantum.drop(['bssid', 'timestamp'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols = df_quantum.columns[:one_hot_columns_count + 3]\n",
    "speed_acc_cols = df_quantum.columns[one_hot_columns_count + 3:]\n",
    "\n",
    "common_funcs_list = [mean, var, median, skew, kurt]\n",
    "special_funcs_list = [mean, pd.DataFrame.mad, skew]\n",
    "\n",
    "common_cols_map = { col : common_funcs_list for col in common_cols }\n",
    "speed_acc_cols_map = { col : special_funcs_list for col in speed_acc_cols }\n",
    "\n",
    "agg_dict = common_cols_map\n",
    "agg_dict.update(speed_acc_cols_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum[speed_acc_cols] = df_quantum[speed_acc_cols].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "D:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "df_sampling = df_quantum.groupby(pd.Grouper(freq = TIME_SAMPLE_FREQ)).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolling = df_quantum.rolling(TIME_SAMPLE_FREQ, min_periods = 1, center = False).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampling.columns = [\"_\".join([str(high_level_name), str(low_level_name)]) \\\n",
    "                       for (high_level_name, low_level_name) in df_sampling.columns.values]\n",
    "\n",
    "df_rolling.columns = [\"_\".join([str(high_level_name), str(low_level_name)]) \\\n",
    "                      for (high_level_name, low_level_name) in df_rolling.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampling = df_sampling.dropna()\n",
    "df_sampling = df_sampling.fillna(0)\n",
    "\n",
    "df_rolling = df_rolling.dropna()\n",
    "df_rolling = df_rolling.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rolling['day_time'] = df_rolling.apply(lambda x: x.name.hour + x.name.minute / 60 , axis = 1)\n",
    "# df_sampling['day_time'] = df_sampling.apply(lambda x: x.name.hour + x.name.minute / 60 , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampling.to_csv(\".\\\\_datasets\\\\5s\\\\bt_sampling_dataset_3.csv\")\n",
    "df_rolling.to_csv(\".\\\\_datasets\\\\5s\\\\bt_rolling_dataset_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
