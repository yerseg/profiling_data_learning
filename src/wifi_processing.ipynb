{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "from scipy.spatial import distance\n",
    "import scipy.stats as stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_SAMPLE_FREQ = '30s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'.\\\\_generated\\\\wifi_1.data' does not exist: b'.\\\\_generated\\\\wifi_1.data'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-83b4e516c64a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m                  names = ['timestamp', 'uuid', 'bssid', 'ssid', 'capabilities', \\\n\u001B[0;32m      3\u001B[0m                           \u001B[1;34m'freq0'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'freq1'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'chwidth'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'freq'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'level'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'operator'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m                           'time', 'venue', '802', 'passpoint'])\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36mparser_f\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[0;32m    700\u001B[0m                     skip_blank_lines=skip_blank_lines)\n\u001B[0;32m    701\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 702\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    703\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    704\u001B[0m     \u001B[0mparser_f\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    427\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    428\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 429\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    430\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    431\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    893\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'has_index_names'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'has_index_names'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    894\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 895\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    896\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    897\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1120\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'c'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1121\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'c'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1122\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mCParserWrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1123\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1124\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'python'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m   1851\u001B[0m         \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'usecols'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0musecols\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1852\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1853\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mparsers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTextReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1854\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munnamed_cols\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munnamed_cols\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1855\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] File b'.\\\\_generated\\\\wifi_1.data' does not exist: b'.\\\\_generated\\\\wifi_1.data'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\".\\\\_generated\\\\wifi_1.data\", index_col = False, header = None, low_memory = False, \\\n",
    "                 names = ['timestamp', 'uuid', 'bssid', 'ssid', 'capabilities', \\\n",
    "                          'freq0', 'freq1', 'chwidth', 'freq', 'level', 'operator', \\\n",
    "                          'time', 'venue', '802', 'passpoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = df['timestamp'].apply(lambda x: dt.strptime(x, '%d.%m.%Y_%H:%M:%S.%f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.DatetimeIndex(df.timestamp)\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['timestamp', 'chwidth', 'operator', 'venue', '802', 'time', 'ssid', 'capabilities', \\\n",
    "              'passpoint', 'freq0', 'freq1'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bssid_map = { bssid.replace(' ', ''): idx for bssid, idx in zip(df.bssid.unique(), range(len(df.bssid.unique()))) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bssid = df.bssid.apply(lambda x: str(x).replace(' ', ''))\n",
    "df.level = df.level.apply(lambda x: str(x).replace(' ', ''))\n",
    "df.freq = df.freq.apply(lambda x: str(x).replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bssid_level'] = df[['bssid', 'level']].agg(','.join, axis=1)\n",
    "df['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_string_join(col):\n",
    "    col = col.apply(lambda x: str(x))\n",
    "    return col.str.cat(sep = ',').replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_bssid_col(col):\n",
    "    array_len = len(bssid_map)\n",
    "    array = np.zeros(array_len, dtype = 'float')\n",
    "    def fill_array(x):\n",
    "        tmp = x.split(',')\n",
    "        bssid = tmp[0]\n",
    "        level = float(tmp[1])\n",
    "        array[bssid_map[bssid.replace(' ', '')]] = level\n",
    "        return\n",
    "        \n",
    "    col.apply(lambda x: fill_array(x))\n",
    "    return np.array2string(array, separator = ',').replace(' ', '')[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_func_dicts_quantum = { 'freq': agg_string_join, 'level': agg_string_join, 'bssid_level' : agg_bssid_col, 'count' : 'sum' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum = df.groupby(['timestamp', 'uuid'], as_index=True).agg(all_func_dicts_quantum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum = df_quantum.reset_index()\n",
    "df_quantum.index = pd.DatetimeIndex(df_quantum.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum = df_quantum[df_quantum['count'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conn = pd.read_csv(\".\\\\_generated\\\\conn_wifi_5.data\", index_col = False, header = None, low_memory = False, \\\n",
    "                 names = ['timestamp', 'uuid', 'stamp', 'bssid', '1', '2', '3', '4', '5', '6', 'level', '8'])\n",
    "\n",
    "df_conn = df_conn.drop(df_conn.columns.difference(['bssid','timestamp', 'level']), axis = 1)\n",
    "df_conn['timestamp'] = df_conn['timestamp'].apply(lambda x: dt.strptime(x, '%d.%m.%Y_%H:%M:%S.%f'))\n",
    "df_conn.index = pd.DatetimeIndex(df_conn.timestamp)\n",
    "df_conn = df_conn.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level_from_row(row):\n",
    "    bssid = df_conn.iloc[df_conn.index.get_loc(row.name, method = 'nearest')]['bssid']\n",
    "    if str(bssid) == 'nan' or str(bssid) == 'null' or str(bssid) == '':\n",
    "        return 0\n",
    "    \n",
    "    level = df_conn.iloc[df_conn.index.get_loc(row.name, method = 'nearest')]['level']\n",
    "    time = df_conn.iloc[df_conn.index.get_loc(row.name, method = 'nearest')]['timestamp']\n",
    "    return level if abs((time - row.name).total_seconds()) <= 10 else 0\n",
    "\n",
    "\n",
    "df_quantum['conn_level'] = df_quantum.apply(lambda row: get_level_from_row(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2array(string):\n",
    "    try:\n",
    "        array = np.fromstring(string, sep=',')\n",
    "        return array\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def to_ones_array(array):\n",
    "    try:\n",
    "        array[array != 0] = 1\n",
    "        return array\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_len(obj):\n",
    "    try:\n",
    "        length = len(obj)\n",
    "        return length\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occured_nets_count(row, prev_col, curr_col):\n",
    "    prev = to_ones_array(string2array(row[prev_col]))\n",
    "    curr = to_ones_array(string2array(row[curr_col]))\n",
    "    intersection = np.logical_and(curr, prev)\n",
    "    diff = np.logical_and(curr, np.logical_not(intersection))\n",
    "    \n",
    "    if (np.count_nonzero(np.logical_or(prev, curr)) == 0):\n",
    "        return 0\n",
    "    \n",
    "    return np.count_nonzero(diff) / np.count_nonzero(np.logical_or(prev, curr))\n",
    "\n",
    "def get_disappeared_nets_count(row, prev_col, curr_col):\n",
    "    prev = to_ones_array(string2array(row[prev_col]))\n",
    "    curr = to_ones_array(string2array(row[curr_col]))\n",
    "    intersection = np.logical_and(curr, prev)\n",
    "    diff = np.logical_and(prev, np.logical_not(intersection))\n",
    "    \n",
    "    if (np.count_nonzero(np.logical_or(prev, curr)) == 0):\n",
    "        return 0\n",
    "    \n",
    "    return np.count_nonzero(diff) / np.count_nonzero(np.logical_or(prev, curr))\n",
    "\n",
    "def get_jaccard_index(row, prev_col, curr_col):\n",
    "    prev = to_ones_array(string2array(row[prev_col]))\n",
    "    curr = to_ones_array(string2array(row[curr_col]))\n",
    "    return distance.jaccard(prev, curr)\n",
    "\n",
    "def get_occur_speed(row, prev_col, curr_col):\n",
    "    prev = to_ones_array(string2array(row[prev_col]))\n",
    "    curr = to_ones_array(string2array(row[curr_col]))\n",
    "    return np.linalg.norm(prev - curr) / np.sqrt(get_len(prev))\n",
    "    \n",
    "def get_level_speed(row, prev_col, curr_col):\n",
    "    prev = string2array(row[prev_col])\n",
    "    curr = string2array(row[curr_col])\n",
    "    return np.linalg.norm(prev - curr) / np.sqrt(get_len(prev))\n",
    "\n",
    "def calc_single_cols_in_window(df, col, new_col, window, func):\n",
    "    def func_wrapper(func, row, prev_col, curr_col):\n",
    "        delta = row.timestamp - row.prev_timestamp\n",
    "        if pd.isnull(delta):\n",
    "            delta = 0\n",
    "        else:\n",
    "            delta = abs(delta.total_seconds())\n",
    "        if delta > 10 * 60:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return func(row, prev_col_name, col)\n",
    "        \n",
    "    new_cols = []\n",
    "        \n",
    "    for i in range(window):\n",
    "        prev_col_name = \"_\".join(['prev', col, str(i + 1)])\n",
    "        new_col_name = \"_\".join([new_col, str(i + 1)])\n",
    "        \n",
    "        df['prev_timestamp'] = df.timestamp.shift(i + 1)\n",
    "        df[prev_col_name] = df[col].shift(i + 1)\n",
    "        df[new_col_name] = df.apply(lambda row: func_wrapper(func, row, prev_col_name, col), axis = 1)\n",
    "        df = df.drop(prev_col_name, axis = 1)\n",
    "        df = df.drop('prev_timestamp', axis = 1)\n",
    "        new_cols.append(new_col_name)\n",
    "        \n",
    "    df[\"_\".join([new_col, 'mean'])] = df[new_cols].mean(axis = 1)\n",
    "    df[\"_\".join([new_col, 'median'])] = df[new_cols].median(axis = 1)\n",
    "    df[\"_\".join([new_col, 'var'])] = df[new_cols].var(axis = 1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 3\n",
    "\n",
    "occur_and_level_columns_map = [\n",
    "    (\"bssid_level\", \"occured_nets_count\", WINDOW_SIZE, get_occured_nets_count),\n",
    "    (\"bssid_level\", \"disappeared_nets_count\", WINDOW_SIZE, get_disappeared_nets_count),\n",
    "    (\"bssid_level\", \"jaccard_index\", WINDOW_SIZE, get_jaccard_index), \n",
    "    (\"bssid_level\", \"occur_speed\", WINDOW_SIZE, get_occur_speed),\n",
    "    (\"bssid_level\", \"level_speed\", WINDOW_SIZE, get_level_speed)\n",
    "]\n",
    "\n",
    "for (col, new_col, window, func) in occur_and_level_columns_map:\n",
    "    df_quantum = calc_single_cols_in_window(df_quantum, col, new_col, window, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conn_level_speed(row, prev_col, curr_col):\n",
    "    return row[curr_col] - row[prev_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 3\n",
    "\n",
    "single_columns_map = [\n",
    "    (\"conn_level\", \"conn_level_speed\", WINDOW_SIZE, get_conn_level_speed),\n",
    "    (\"count\", \"count_speed\", WINDOW_SIZE, get_conn_level_speed)\n",
    "]\n",
    "\n",
    "for (col, new_col, window, func) in single_columns_map:\n",
    "    df_quantum = calc_single_cols_in_window(df_quantum, col, new_col, window, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acceleration(row, prev_col, curr_col):\n",
    "    return abs(row[curr_col] - row[prev_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 3\n",
    "\n",
    "multi_speed_cols = [\"occured_nets_count_mean\", \"jaccard_index_mean\", \"occur_speed_mean\", \"disappeared_nets_count_mean\", \n",
    "                    \"conn_level_speed_mean\", \"count_speed_mean\"]\n",
    "\n",
    "for col in multi_speed_cols:\n",
    "    df_quantum = calc_single_cols_in_window(df_quantum, col, \"_\".join([\"acceleration\", col]), window, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_str(col):\n",
    "#     all_freq = col.str.cat(sep=',')\n",
    "    return string2array(col)\n",
    "\n",
    "def str_mean(col):\n",
    "    array = agg_str(col)\n",
    "    if str(array) == 'nan':\n",
    "        return 0 \n",
    "    return np.mean(array)\n",
    "\n",
    "# def str_var(col):\n",
    "#     array = agg_str(col)\n",
    "#     if str(array) == 'nan':\n",
    "#         return 0 \n",
    "#     return np.var(array)\n",
    "\n",
    "# def str_median(col):\n",
    "#     array = agg_str(col)\n",
    "#     if str(array) == 'nan':\n",
    "#         return 0 \n",
    "#     return np.median(array)\n",
    "\n",
    "# def str_skew(col):\n",
    "#     array = agg_str(col)\n",
    "#     if str(array) == 'nan':\n",
    "#         return 0 \n",
    "#     return stats.skew(array)\n",
    "\n",
    "# def str_kurt(col):\n",
    "#     array = agg_str(col)\n",
    "#     if str(array) == 'nan':\n",
    "#         return 0 \n",
    "#     return stats.kurtosis(array)\n",
    "\n",
    "def mean(col):\n",
    "    return np.mean(col)\n",
    "\n",
    "def var(col):\n",
    "    return np.var(col)\n",
    "\n",
    "def median(col):\n",
    "    return np.median(col)\n",
    "\n",
    "def skew(col):\n",
    "    return stats.skew(col)\n",
    "\n",
    "def kurt(col):\n",
    "    return stats.kurtosis(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum['freq'] = df_quantum.apply(lambda row: str_mean(row['freq']), axis = 1)\n",
    "df_quantum['level'] = df_quantum.apply(lambda row: str_mean(row['level']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum = df_quantum.drop(['bssid_level', 'timestamp', 'uuid'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string_common_cols = df_quantum.columns[1:3]\n",
    "common_cols = df_quantum.columns[1:5]\n",
    "speed_acc_cols = df_quantum.columns[5:]\n",
    "\n",
    "# string_common_funcs_list = [str_mean, str_var, str_median, str_skew, str_kurt]\n",
    "common_funcs_list = [mean, var, median, skew, kurt]\n",
    "special_funcs_list = [mean, pd.DataFrame.mad, skew]\n",
    "\n",
    "common_cols_map = { col : common_funcs_list for col in common_cols }\n",
    "# string_common_cols_map = { col : string_common_funcs_list for col in string_common_cols }\n",
    "speed_acc_cols_map = { col : special_funcs_list for col in speed_acc_cols }\n",
    "\n",
    "agg_dict = common_cols_map\n",
    "# agg_dict.update(string_common_cols_map)\n",
    "agg_dict.update(speed_acc_cols_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantum[speed_acc_cols] = df_quantum[speed_acc_cols].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampling = df_quantum.groupby(pd.Grouper(freq = TIME_SAMPLE_FREQ)).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolling = df_quantum.rolling(TIME_SAMPLE_FREQ, min_periods = 1, center = False).agg(agg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampling.columns = [\"_\".join([str(high_level_name), str(low_level_name)]) \\\n",
    "                       for (high_level_name, low_level_name) in df_sampling.columns.values]\n",
    "\n",
    "df_rolling.columns = [\"_\".join([str(high_level_name), str(low_level_name)]) \\\n",
    "                      for (high_level_name, low_level_name) in df_rolling.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampling = df_sampling.dropna()\n",
    "df_sampling = df_sampling.fillna(0)\n",
    "\n",
    "df_rolling = df_rolling.dropna()\n",
    "df_rolling = df_rolling.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rolling['day_time'] = df_rolling.apply(lambda x: x.name.hour + x.name.minute / 60 , axis = 1)\n",
    "# df_sampling['day_time'] = df_sampling.apply(lambda x: x.name.hour + x.name.minute / 60 , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampling.to_csv(\".\\\\_datasets\\\\5s\\\\wifi_sampling_dataset_5.csv\")\n",
    "df_rolling.to_csv(\".\\\\_datasets\\\\5s\\\\wifi_rolling_dataset_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}